{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data from scraped reviews\n",
    "## Import needed dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#nlp = spacy.load('en_core_web_md')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scraped reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review from Fertility IQ\n",
    "df = pd.read_csv('../scrape/scraped_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is scraped as questions and answers. The following code creates a single column for questions and a single column for answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df1 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 1','Answer 1']]\n",
    "df1['Question'] = df1['Question 1']\n",
    "df1['Answer']   = df1['Answer 1']\n",
    "df2 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 2','Answer 2']]\n",
    "df2['Question'] = df2['Question 2']\n",
    "df2['Answer']   = df2['Answer 2']\n",
    "df3 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 3','Answer 3']]\n",
    "df3['Question'] = df3['Question 3']\n",
    "df3['Answer']   = df3['Answer 3']\n",
    "df4 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 4','Answer 4']]\n",
    "df4['Question'] = df4['Question 4']\n",
    "df4['Answer']   = df4['Answer 4']\n",
    "df5 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 5','Answer 5']]\n",
    "df5['Question'] = df5['Question 5']\n",
    "df5['Answer']   = df5['Answer 5']\n",
    "df6 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 6','Answer 6']]\n",
    "df6['Question'] = df6['Question 6']\n",
    "df6['Answer']   = df6['Answer 6']\n",
    "df7 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 7','Answer 7']]\n",
    "df7['Question'] = df7['Question 7']\n",
    "df7['Answer']   = df7['Answer 7']\n",
    "df8 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 8','Answer 8']]\n",
    "df8['Question'] = df8['Question 8']\n",
    "df8['Answer']   = df8['Answer 8']\n",
    "df9 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 9','Answer 9']]\n",
    "df9['Question'] = df9['Question 9']\n",
    "df9['Answer']   = df9['Answer 9']\n",
    "df10 = df[['clinic_name','avg_clinic_score','avg_doc_score','success','income','Question 10','Answer 10']]\n",
    "df10['Question'] = df10['Question 10']\n",
    "df10['Answer']   = df10['Answer 10']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = df_qa.drop(['Question 1','Answer 1','Question 2','Answer 2','Question 3','Answer 3','Question 4','Answer 4',\n",
    "                   'Question 5','Answer 5','Question 6','Answer 6','Question 7','Answer 7','Question 8','Answer 8',\n",
    "                   'Question 9','Answer 9','Question 10','Answer 10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns\n",
    "df_qa = df_qa.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_q (val):\n",
    "    if val[:28]=='How was your experience with':\n",
    "        val = 'Doctor'   # classify under doctor\n",
    "    elif val[:16] =='During treatment':  # Treated like num or human\n",
    "        val = \"Doctor\"   # classify under doctor\n",
    "    elif val[:16] == \"What's one piece\":\n",
    "        val = 'Advice'\n",
    "    elif val[:40] == \"Describe your experience with your nurse\":\n",
    "        val = \"Nurse\"\n",
    "    elif val[:42] == \"Describe your experience with your nursing\":\n",
    "        val = \"Nurse\"\n",
    "    elif val[:29]==\"Describe your experience with\":\n",
    "        val = \"Clinic\"\n",
    "    elif val[:22] == \"Describe the protocols\":\n",
    "        val = \"Protocols\"\n",
    "    elif val[:18]== \"Describe the costs\":\n",
    "        val = \"Cost\"\n",
    "    elif val[:31] == \"What specific things went wrong\":\n",
    "        val = \"Problems\"\n",
    "    else:\n",
    "        if \"eSET\" in val:\n",
    "            val = \"Protocols\"\n",
    "        else:\n",
    "            val=val\n",
    "       \n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa.Question = df_qa.Question.apply(replace_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Doctor\n",
      "1 Advice\n",
      "2 Nurse\n",
      "3 Clinic\n",
      "4 Protocols\n",
      "5 Cost\n",
      "6 Problems\n"
     ]
    }
   ],
   "source": [
    "for i,q in enumerate (df_t.Question.unique()):\n",
    "    #if type(q)==float:\n",
    "    print (i, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Scraped data from Fertility IQ needs special cleaning since it appears as html text. This will help further clean these responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def failed_list(text):\n",
    "    if \"<ul\" in text:\n",
    "        text_list = text.split(\">\")\n",
    "        fail_list =[]\n",
    "        for i in text_list:\n",
    "            if \"</li\" in i:\n",
    "                fail_list.append(i.split('<')[0])\n",
    "        doc = ', '.join(fail_list)\n",
    "        return doc\n",
    "    \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.Answer = df_t.Answer.apply(failed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save partially clean reviews to csv\n",
    "df_t.to_csv('fiq_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text\n",
    "## 1) Punctuation\n",
    "## 2) Contractions\n",
    "## 3) Stop Words\n",
    "## 4) Lemetaziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jacobberger/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jacobberger/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "#wt = nltk.word_tokenizer()\n",
    "#list of words to not remove\n",
    "remove_form_stop_words = ['no','not',\"aren't\",\"couldn't\",\"didn't\",\"doesn't\",\n",
    "                          \"wasn't\",\"wouldn't\",\"won't\",\"don't\",\"isn't\",\"shouldn't\"]\n",
    "for w in remove_form_stop_words:\n",
    "    en_stop.remove(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"aren't\": \"are not,\n",
    "\"can't\": \"cannot\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"isn't\": \"is not\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"weren't\": \"were not\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    #doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    punc_list = ['.',',',\"!\",'*','?','-','/','\"','(',')','#']\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    \n",
    "    doc = doc.split(\" \")\n",
    "    # Contractions in text \n",
    "    new_doc=[]\n",
    "    for token in doc:\n",
    "        if token in contractions:\n",
    "            new_doc.append(contractions[token])\n",
    "        else:\n",
    "            new_doc.append(token)\n",
    "    doc = ' '.join(new_doc)\n",
    "    \n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    \n",
    "    tokens = [token for token in tokens]\n",
    "    # Contractions in text    \n",
    "    for token in tokens:\n",
    "        if token in contractions:\n",
    "            token = contractions[token]\n",
    "            \n",
    "    # Remove Punctuation\n",
    "    tokens = [token for token in tokens if token.strip() not in punc_list]\n",
    "    \n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in en_stop]\n",
    "    \n",
    "    #Lemmatize tokens\n",
    "    lemm_tokens = [get_lemma(token) for token in filtered_tokens]\n",
    "    \n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(lemm_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t['Clean_Text'] = df_t.Answer.apply(simple_clean_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.to_csv('fiq_clean_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD TEXT CLEANING PROCESS\n",
    "#def preprocessor(text):\n",
    "#    if type(text) == str:\n",
    "#        text = re.sub('<[^>]*>', '', text)\n",
    "#        text = re.sub('[\\W]+', '', text.lower())\n",
    "#    return text\n",
    "\n",
    "\n",
    "\n",
    "#def spacy_clean_text(review):\n",
    "                 \n",
    "#    nlp = English()\n",
    "#    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "#    tokens = tokenizer(review)\n",
    "    \n",
    "#    lemma_list = []\n",
    "#    n=0\n",
    "#    for token in tokens:\n",
    "#        if token.is_stop is False:\n",
    "#            token_preprocessed = preprocessor(token.lemma_)\n",
    "#            if token_preprocessed != '':\n",
    "#                lemma_list.append(token_preprocessed)\n",
    "#    text = ' '.join(lemma_list)           \n",
    "#    #return (lemma_list)\n",
    "#    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(df_t.Clean_Text, df_t.Question, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vsc = vec.fit_transform(data.clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit_transform(data_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 132    0    0   46  367    0    1    0]\n",
      " [   0  434    0   25   21    0    4    0]\n",
      " [   1    2  123    2  107    0    9    0]\n",
      " [   0    1    0  820  187    0    1    0]\n",
      " [   0    0    0   60 1100    1    6    0]\n",
      " [   0    0    0  131  164   11    0    0]\n",
      " [   1    4    0    1   97    0  361    0]\n",
      " [   0    0    0    0    0    0    0  175]]\n",
      "\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "  advice give prospective patient       0.99      0.24      0.39       546\n",
      "                             cost       0.98      0.90      0.94       484\n",
      "eSET vs. multiple embryo transfer       1.00      0.50      0.67       244\n",
      "           experience with clinic       0.76      0.81      0.78      1009\n",
      "           experience with doctor       0.54      0.94      0.69      1167\n",
      "            experience with nurse       0.92      0.04      0.07       306\n",
      "            protocols and success       0.95      0.78      0.85       464\n",
      "       specific things went wrong       1.00      1.00      1.00       175\n",
      "\n",
      "                         accuracy                           0.72      4395\n",
      "                        macro avg       0.89      0.65      0.67      4395\n",
      "                     weighted avg       0.81      0.72      0.69      4395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 113   57    0  365    1    0    1]\n",
      " [   1  816    0  155    0    0    4]\n",
      " [   0   16  426   20    0    0    7]\n",
      " [   1   68    0 1123    0    0   16]\n",
      " [   0  131    0  192   11    0    0]\n",
      " [   0    0    0    0    0  173    0]\n",
      " [   0    7    5  118    0    0  622]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Advice       0.98      0.21      0.35       537\n",
      "      Clinic       0.75      0.84      0.79       976\n",
      "        Cost       0.99      0.91      0.95       469\n",
      "      Doctor       0.57      0.93      0.71      1208\n",
      "       Nurse       0.92      0.03      0.06       334\n",
      "    Problems       1.00      1.00      1.00       173\n",
      "   Protocols       0.96      0.83      0.89       752\n",
      "\n",
      "    accuracy                           0.74      4449\n",
      "   macro avg       0.88      0.68      0.68      4449\n",
      "weighted avg       0.81      0.74      0.70      4449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "SVM = svm.SVC(C=5) # default kernel = ’rbf’\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vec', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', SVM),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', SVC(C=5))])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 421   42    5   90    7    0   12]\n",
      " [  28  838    3   77   57    0    7]\n",
      " [   5    9  441    2    0    0   15]\n",
      " [  32   75    1 1020    9    0   33]\n",
      " [  11  103    1   44  163    0    2]\n",
      " [   0    0    0    0    0  175    0]\n",
      " [  13    3    6   33    0    0  666]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Advice       0.83      0.73      0.77       577\n",
      "      Clinic       0.78      0.83      0.81      1010\n",
      "        Cost       0.96      0.93      0.95       472\n",
      "      Doctor       0.81      0.87      0.84      1170\n",
      "       Nurse       0.69      0.50      0.58       324\n",
      "    Problems       1.00      1.00      1.00       175\n",
      "   Protocols       0.91      0.92      0.91       721\n",
      "\n",
      "    accuracy                           0.84      4449\n",
      "   macro avg       0.85      0.83      0.84      4449\n",
      "weighted avg       0.84      0.84      0.83      4449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Yelp Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = pd.read_csv('../scrape/yelp_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yelp.Ratings[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, rev in enumerate (df_yelp.Reviews):\n",
    "    char = False\n",
    "    for n in re.findall(r'[\\u4e00-\\u9fff]+', rev):\n",
    "        char = True\n",
    "        #print(i,n)\n",
    "    if char:\n",
    "        df_yelp = df_yelp.drop(i,axis=0)\n",
    "        char = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yelp = df_yelp.drop(129,axis=0)\n",
    "df_yelp.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = df_yelp.drop(['Unnamed: 0','index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_up_review(df):\n",
    "    df_final = pd.DataFrame()\n",
    "    for c in df.Clinic_name.unique():\n",
    "        \n",
    "        df_temp = df[df.Clinic_name == c]\n",
    "        \n",
    "        ratings = []\n",
    "        sentences = []\n",
    "        #id = c + \"_\" + str(0)\n",
    "        for i, r in enumerate (df_temp.Reviews):\n",
    "            list_of_sentences = r.replace(\"Dr.\",\"Dr\").strip().split(\".\")\n",
    "             \n",
    "            sentences = sentences + list_of_sentences\n",
    "            \n",
    "            r = []\n",
    "            for x in range(0, len(list_of_sentences)):\n",
    "                r.append(df.Ratings[i][0])\n",
    "            ratings = ratings + r\n",
    "            #print(len(ratings))\n",
    "        #print(len(sentences))\n",
    "            \n",
    "        df_new = pd.DataFrame(sentences,columns=['Reviews_by_sentence'])\n",
    "        df_new['Clinic'] = c\n",
    "        df_new['Ratings'] = ratings\n",
    "        df_final = pd.concat([df_final,df_new],ignore_index=True)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6820"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_split = split_up_review(df_yelp)\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate (df_y_split.Reviews_by_sentence):\n",
    "    if len(r) < 11:\n",
    "        #print (i,r)\n",
    "        df_y_split.drop(i,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5939"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_y_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_split.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews_by_sentence</th>\n",
       "      <th>Clinic</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Columbia University Fertility center is an exc...</td>\n",
       "      <td>Columbia University Fertility</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We were seen by Dr Paula Brady at the Columbi...</td>\n",
       "      <td>Columbia University Fertility</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She is an excellent doctor, who treats her pa...</td>\n",
       "      <td>Columbia University Fertility</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr Brady took care of us and everything worke...</td>\n",
       "      <td>Columbia University Fertility</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Clinic as a whole is also very good as it ...</td>\n",
       "      <td>Columbia University Fertility</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>I'm in the middle of my treatments with them ...</td>\n",
       "      <td>Penn Fertility Care</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>They have also been individualized in their b...</td>\n",
       "      <td>Penn Fertility Care</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>The doctors are all excellent-- we've gotten ...</td>\n",
       "      <td>Penn Fertility Care</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>The nursing staff is the same way</td>\n",
       "      <td>Penn Fertility Care</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>My nurse communicates via text when I need to...</td>\n",
       "      <td>Penn Fertility Care</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5939 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Reviews_by_sentence  \\\n",
       "0     Columbia University Fertility center is an exc...   \n",
       "1      We were seen by Dr Paula Brady at the Columbi...   \n",
       "2      She is an excellent doctor, who treats her pa...   \n",
       "3      Dr Brady took care of us and everything worke...   \n",
       "4     The Clinic as a whole is also very good as it ...   \n",
       "...                                                 ...   \n",
       "5934   I'm in the middle of my treatments with them ...   \n",
       "5935   They have also been individualized in their b...   \n",
       "5936   The doctors are all excellent-- we've gotten ...   \n",
       "5937                  The nursing staff is the same way   \n",
       "5938   My nurse communicates via text when I need to...   \n",
       "\n",
       "                             Clinic Ratings  \n",
       "0     Columbia University Fertility       5  \n",
       "1     Columbia University Fertility       5  \n",
       "2     Columbia University Fertility       5  \n",
       "3     Columbia University Fertility       5  \n",
       "4     Columbia University Fertility       5  \n",
       "...                             ...     ...  \n",
       "5934            Penn Fertility Care       5  \n",
       "5935            Penn Fertility Care       5  \n",
       "5936            Penn Fertility Care       5  \n",
       "5937            Penn Fertility Care       5  \n",
       "5938            Penn Fertility Care       5  \n",
       "\n",
       "[5939 rows x 3 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add columm for clean yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yelp_split.clean_answers = df_yelp_split.clean_answers.apply(spacy_clean_text)\n",
    "df_y_split['clean_answers'] = df_y_split.Reviews_by_sentence.apply(simple_clean_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_answers</th>\n",
       "      <th>Reviews_by_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>columbia university fertility center excellent...</td>\n",
       "      <td>Columbia University Fertility center is an exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>see dr paula brady columbia university clinic</td>\n",
       "      <td>We were seen by Dr Paula Brady at the Columbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent doctor treat patient personal level</td>\n",
       "      <td>She is an excellent doctor, who treats her pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dr brady take care us everything work great us</td>\n",
       "      <td>Dr Brady took care of us and everything worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clinic whole also good open patient holiday we...</td>\n",
       "      <td>The Clinic as a whole is also very good as it ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean_answers  \\\n",
       "0  columbia university fertility center excellent...   \n",
       "1      see dr paula brady columbia university clinic   \n",
       "2      excellent doctor treat patient personal level   \n",
       "3     dr brady take care us everything work great us   \n",
       "4  clinic whole also good open patient holiday we...   \n",
       "\n",
       "                                 Reviews_by_sentence  \n",
       "0  Columbia University Fertility center is an exc...  \n",
       "1   We were seen by Dr Paula Brady at the Columbi...  \n",
       "2   She is an excellent doctor, who treats her pa...  \n",
       "3   Dr Brady took care of us and everything worke...  \n",
       "4  The Clinic as a whole is also very good as it ...  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_split[['clean_answers','Reviews_by_sentence']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a7658c210>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARcUlEQVR4nO3de7BdZX3G8e9jAmJFBeVokVDDKOMUbYuaAafMaAsO4DVUxcHxEi0t7RStTm0VO613HKxVVLzMUEHBOiJVkWitNuU6UgETbnKpkqrVCCXRIEotVPDXP/Ybc4CTvDsx+6wdzvczs2ev9a53rfPb65/nvGu9e+1UFZIkbc0Dhi5AkjT9DAtJUpdhIUnqMiwkSV2GhSSpa/HQBUzCXnvtVUuXLh26DEnaqaxZs+aHVTUz17b7ZVgsXbqU1atXD12GJO1UkvzXlrZ5GUqS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktR1v/wGtyTtCB983ReGLmGHe9V7nrtd+zmykCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkromHRZJFSa5M8sW2vl+Sy5LcmOTTSXZt7Q9s62vb9qWzjvHG1v7NJEdMumZJ0j3Nx8jiNcANs9bfBZxcVfsDtwLHtvZjgVur6nHAya0fSQ4AjgGeABwJfDjJonmoW5LUTDQskiwBng18tK0HOBT4TOtyBnBUW17e1mnbD2v9lwNnVdWdVfUdYC1w0CTrliTd06RHFu8DXg/8oq0/AvhxVd3V1tcB+7TlfYDvA7Ttt7X+v2yfY59fSnJcktVJVm/YsGFHfw5JWtAmFhZJngOsr6o1s5vn6FqdbVvbZ3ND1alVtayqls3MzGxzvZKkLVs8wWMfAjwvybOA3YCHMhpp7JFkcRs9LAFuav3XAfsC65IsBh4GbJzVvsnsfSRJ82BiI4uqemNVLamqpYxuUJ9fVS8BLgBe2LqtAM5tyyvbOm37+VVVrf2YNltqP2B/4PJJ1S1Juq9Jjiy25A3AWUneAVwJnNbaTwM+kWQtoxHFMQBVdV2Ss4HrgbuA46vq7vkvW5IWrnkJi6q6ELiwLX+bOWYzVdUdwNFb2P9E4MTJVShJ2hq/wS1J6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSuiYVFkt2SXJ7k6iTXJXlra98vyWVJbkzy6SS7tvYHtvW1bfvSWcd6Y2v/ZpIjJlWzJGlukxxZ3AkcWlW/AxwIHJnkqcC7gJOran/gVuDY1v9Y4NaqehxwcutHkgOAY4AnAEcCH06yaIJ1S5LuZWJhUSO3t9Vd2quAQ4HPtPYzgKPa8vK2Ttt+WJK09rOq6s6q+g6wFjhoUnVLku5rovcskixKchWwHlgF/Cfw46q6q3VZB+zTlvcBvg/Qtt8GPGJ2+xz7zP5bxyVZnWT1hg0bJvFxJGnBmmhYVNXdVXUgsITRaOA35+rW3rOFbVtqv/ffOrWqllXVspmZme0tWZI0h3mZDVVVPwYuBJ4K7JFkcdu0BLipLa8D9gVo2x8GbJzdPsc+kqR5MMnZUDNJ9mjLDwKeAdwAXAC8sHVbAZzblle2ddr286uqWvsxbbbUfsD+wOWTqluSdF+L+122297AGW3m0gOAs6vqi0muB85K8g7gSuC01v804BNJ1jIaURwDUFXXJTkbuB64Czi+qu6eYN2SpHuZWFhU1TXAk+Zo/zZzzGaqqjuAo7dwrBOBE3d0jZKk8fgNbklSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHWNFRZJzhunTZJ0/7TVR5Qn2Q34NWCvJHuy+SdOHwo8esK1SZKmRO/3LP4EeC2jYFjD5rD4CfChCdYlSZoiWw2Lqno/8P4kr66qU+apJknSlBnrl/Kq6pQkvwssnb1PVZ05obokSVNkrLBI8gngscBVwKbfvy7AsJCkBWDc3+BeBhxQVTXJYiRJ02nc71lcC/z6JAuRJE2vcUcWewHXJ7kcuHNTY1U9byJVSZKmyrhh8ZZJFiFJmm7jzoa6aNKFSJKm17izoX7KaPYTwK7ALsD/VNVDJ1WYJGl6jDuyeMjs9SRHAQdNpCJJ0tTZrqfOVtXngUN3cC2SpCk17mWo589afQCj7134nQtJWiDGnQ313FnLdwHfBZbv8GokSVNp3HsWr5x0IZKk6TXujx8tSXJOkvVJbkny2SRLJl2cJGk6jHuD+2PASka/a7EP8IXWJklaAMYNi5mq+lhV3dVeHwdmJliXJGmKjBsWP0zy0iSL2uulwI8mWZgkaXqMGxZ/CLwI+G/gZuCFgDe9JWmBGHfq7NuBFVV1K0CShwN/zyhEJEn3c+OOLH57U1AAVNVG4EmTKUmSNG3GDYsHJNlz00obWWx1VJJk3yQXJLkhyXVJXrNp3ySrktzY3vds7UnygSRrk1yT5MmzjrWi9b8xyYpt/5iSpF/FuJeh3gP8e5LPMHrMx4uAEzv73AW8rqquSPIQYE2SVcArgPOq6qQkJwAnAG8Angns314HAx8BDm7B9GY2P2JkTZKVs0c6kqTJGmtkUVVnAi8AbgE2AM+vqk909rm5qq5oyz8FbmD0HY3lwBmt2xnAUW15OXBmjVwK7JFkb+AIYFVVbWwBsQo4chs+oyTpVzTuyIKquh64fnv+SJKljO5xXAY8qqpubse8OckjW7d9gO/P2m1da9tSuyRpnmzXI8q3RZLdgc8Cr62qn2yt6xxttZX2e/+d45KsTrJ6w4YN21esJGlOEw2LJLswCopPVtXnWvMt7fIS7X19a18H7Dtr9yXATVtpv4eqOrWqllXVspkZv1wuSTvSxMIiSYDTgBuq6r2zNq0ENs1oWgGcO6v95W1W1FOB29rlqq8AhyfZs82cOry1SZLmydj3LLbDIcDLgG8kuaq1/TVwEnB2kmOB7wFHt21fAp4FrAV+RvuGeFVtTPJ24Out39va9zwkSfNkYmFRVV9l7vsNAIfN0b+A47dwrNOB03dcdZKkbTHxG9ySpJ2fYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqSuiYVFktOTrE9y7ay2hydZleTG9r5na0+SDyRZm+SaJE+etc+K1v/GJCsmVa8kacsWT/DYHwc+CJw5q+0E4LyqOinJCW39DcAzgf3b62DgI8DBSR4OvBlYBhSwJsnKqrp1e4t6yl+d2e+0E1rz7pcPXYKk+7GJjSyq6mJg472alwNntOUzgKNmtZ9ZI5cCeyTZGzgCWFVVG1tArAKOnFTNkqS5zfc9i0dV1c0A7f2RrX0f4Puz+q1rbVtqv48kxyVZnWT1hg0bdnjhkrSQTcsN7szRVltpv29j1alVtayqls3MzOzQ4iRpoZvvsLilXV6iva9v7euAfWf1WwLctJV2SdI8mu+wWAlsmtG0Ajh3VvvL26yopwK3tctUXwEOT7Jnmzl1eGuTJM2jic2GSvIp4PeAvZKsYzSr6STg7CTHAt8Djm7dvwQ8C1gL/Ax4JUBVbUzyduDrrd/bqureN80lSRM2sbCoqhdvYdNhc/Qt4PgtHOd04PQdWJokaRtNyw1uSdIUMywkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLX4qEL0HC+97bfGrqEifiNN31j6BJ2ahc97elDl7DDPf3ii4YuYafnyEKS1GVYSJK6DAtJUpdhIUnq2mlucCc5Eng/sAj4aFWdNHBJuh855JRDhi5hIi559SVDl6D7iZ1iZJFkEfAh4JnAAcCLkxwwbFWStHDsFGEBHASsrapvV9X/AWcByweuSZIWjFTV0DV0JXkhcGRV/VFbfxlwcFW9alaf44Dj2urjgW/Oe6H3tRfww6GLmBKei808F5t5LjabhnPxmKqamWvDznLPInO03SPlqupU4NT5KWc8SVZX1bKh65gGnovNPBebeS42m/ZzsbNchloH7DtrfQlw00C1SNKCs7OExdeB/ZPsl2RX4Bhg5cA1SdKCsVNchqqqu5K8CvgKo6mzp1fVdQOXNY6puiw2MM/FZp6LzTwXm031udgpbnBLkoa1s1yGkiQNyLCQJHUZFhOQ5PQk65NcO3QtQ0qyb5ILktyQ5Lokrxm6pqEk2S3J5UmubufirUPXNLQki5JcmeSLQ9cypCTfTfKNJFclWT10PVviPYsJSPI04HbgzKp64tD1DCXJ3sDeVXVFkocAa4Cjqur6gUubd0kCPLiqbk+yC/BV4DVVdenApQ0myV8Ay4CHVtVzhq5nKEm+CyyrqqG/kLdVjiwmoKouBjYOXcfQqurmqrqiLf8UuAHYZ9iqhlEjt7fVXdprwf6nlmQJ8Gzgo0PXovEYFpoXSZYCTwIuG7aS4bTLLlcB64FVVbVgzwXwPuD1wC+GLmQKFPCvSda0xxZNJcNCE5dkd+CzwGur6idD1zOUqrq7qg5k9ASCg5IsyEuUSZ4DrK+qNUPXMiUOqaonM3qq9vHtMvbUMSw0Ue36/GeBT1bV54auZxpU1Y+BC4EjBy5lKIcAz2vX6s8CDk3yj8OWNJyquqm9rwfOYfSU7aljWGhi2k3d04Abquq9Q9czpCQzSfZoyw8CngH8x7BVDaOq3lhVS6pqKaNH95xfVS8duKxBJHlwm/xBkgcDhwNTOYvSsJiAJJ8CvgY8Psm6JMcOXdNADgFexug/x6va61lDFzWQvYELklzD6Flnq6pqQU8ZFQCPAr6a5GrgcuCfq+rLA9c0J6fOSpK6HFlIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJDGlOTuNv332iRf2PS9ia303yPJn81af3SSz0y+UmnHc+qsNKYkt1fV7m35DOBbVXXiVvovBb64kJ88rPsPRxbS9vka7Qm6SXZPcl6SK9rvEixvfU4CHttGI+9OsnTTb5wkeUWSzyX5cpIbk/zdpgMnOTbJt5JcmOQfknywtR/dRjVXJ7l4nj+vFrjFQxcg7WySLAIOY/QoE4A7gD+oqp8k2Qu4NMlK4ATgie3hgZtGGrMdyOhJvHcC30xyCnA38LfAk4GfAucDV7f+bwKOqKof9C6BSTuaIwtpfA9qjxj/EfBwYFVrD/DO9iiPf2M04njUGMc7r6puq6o7gOuBxzB6iNxFVbWxqn4O/NOs/pcAH0/yx8CiHfKJpDEZFtL4/reNEh4D7Aoc39pfAswAT2nbbwF2G+N4d85avpvRSD9b6lxVfwr8DbAvcFWSR2zzJ5C2k2EhbaOqug34c+Av2yPYH8bo9xl+nuT3GYUJjC4jPWQbD3858PQkeyZZDLxg04Ykj62qy6rqTcAPGYWGNC+8ZyFth6q6sj0p9Bjgk8AXkqwGrqI9eryqfpTkknZT+1+AD41x3B8keSejXxS8idHlqdva5ncn2Z/R6OM8Nt/LkCbOqbPSlEmye1Xd3kYW5wCnV9U5Q9elhc3LUNL0eUu7kX4t8B3g8wPXIzmykCT1ObKQJHUZFpKkLsNCktRlWEiSugwLSVLX/wNkD46CmfmohQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df_y_split.Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate (df_y_split.clean_answers):\n",
    "    if len(r) < 2:\n",
    "        df_y_split.drop(i,axis=0,inplace=True)\n",
    "        print (i,r)\n",
    "        #df_yelp_split.drop(i,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_split.to_csv('y_clean_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
