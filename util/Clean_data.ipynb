{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLean data from scraped reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../scrape/scraped_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/jacobberger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df1 = df[['clinic_name','clinic_score','doc_score','success','income','Question 1','Answer 1']]\n",
    "df1['Question'] = df1['Question 1']\n",
    "df1['Answer']   = df1['Answer 1']\n",
    "df2 = df[['clinic_name','clinic_score','doc_score','success','income','Question 2','Answer 2']]\n",
    "df2['Question'] = df2['Question 2']\n",
    "df2['Answer']   = df2['Answer 2']\n",
    "df3 = df[['clinic_name','clinic_score','doc_score','success','income','Question 3','Answer 3']]\n",
    "df3['Question'] = df3['Question 3']\n",
    "df3['Answer']   = df3['Answer 3']\n",
    "df4 = df[['clinic_name','clinic_score','doc_score','success','income','Question 4','Answer 4']]\n",
    "df4['Question'] = df4['Question 4']\n",
    "df4['Answer']   = df4['Answer 4']\n",
    "df5 = df[['clinic_name','clinic_score','doc_score','success','income','Question 5','Answer 5']]\n",
    "df5['Question'] = df5['Question 5']\n",
    "df5['Answer']   = df5['Answer 5']\n",
    "df6 = df[['clinic_name','clinic_score','doc_score','success','income','Question 6','Answer 6']]\n",
    "df6['Question'] = df6['Question 6']\n",
    "df6['Answer']   = df6['Answer 6']\n",
    "df7 = df[['clinic_name','clinic_score','doc_score','success','income','Question 7','Answer 7']]\n",
    "df7['Question'] = df7['Question 7']\n",
    "df7['Answer']   = df7['Answer 7']\n",
    "df8 = df[['clinic_name','clinic_score','doc_score','success','income','Question 8','Answer 8']]\n",
    "df8['Question'] = df8['Question 8']\n",
    "df8['Answer']   = df8['Answer 8']\n",
    "df9 = df[['clinic_name','clinic_score','doc_score','success','income','Question 9','Answer 9']]\n",
    "df9['Question'] = df9['Question 9']\n",
    "df9['Answer']   = df9['Answer 9']\n",
    "df10 = df[['clinic_name','clinic_score','doc_score','success','income','Question 10','Answer 10']]\n",
    "df10['Question'] = df10['Question 10']\n",
    "df10['Answer']   = df10['Answer 10']\n",
    "\n",
    "\n",
    "\n",
    "#df_qa = pd.concat(df[['clinic_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9,df10], ignore_index=True)\n",
    "\n",
    "df_t = df_qa.drop(['Question 1','Answer 1','Question 2','Answer 2','Question 3','Answer 3','Question 4','Answer 4',\n",
    "                   'Question 5','Answer 5','Question 6','Answer 6','Question 7','Answer 7','Question 8','Answer 8',\n",
    "                   'Question 9','Answer 9','Question 10','Answer 10'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clinic_name        0\n",
       "clinic_score     360\n",
       "doc_score          0\n",
       "success            0\n",
       "income             0\n",
       "Question        5414\n",
       "Answer          5510\n",
       "dtype: int64"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20340, 7)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_t.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_q (val):\n",
    "    if val[:28]=='How was your experience with':\n",
    "        val = 'experience with doctor'   # classify under doctor\n",
    "    elif val[:16] =='During treatment':  # Treated like num or human\n",
    "        val = \"experience with doctor\"   # classify under doctor\n",
    "    elif val[:16] == \"What's one piece\":\n",
    "        val = 'advice give prospective patient'\n",
    "    elif val[:40] == \"Describe your experience with your nurse\":\n",
    "        val = \"experience with nurse\"\n",
    "    elif val[:42] == \"Describe your experience with your nursing\":\n",
    "        val = \"experience with nurse\"\n",
    "    elif val[:29]==\"Describe your experience with\":\n",
    "        val = \"experience with clinic\"\n",
    "    elif val[:22] == \"Describe the protocols\":\n",
    "        val = \"protocols and success\"\n",
    "    elif val[:18]== \"Describe the costs\":\n",
    "        val = \"cost\"\n",
    "    elif val[:31] == \"What specific things went wrong\":\n",
    "        val = \"specific things went wrong\"\n",
    "    else:\n",
    "        if \"eSET\" in val:\n",
    "            val = \"eSET vs. multiple embryo transfer\"\n",
    "        else:\n",
    "            val=val\n",
    "       \n",
    "    return val\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = data[data.Question==\"experience with nurse\"]['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1075"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.Question = df_t.Question.apply(replace_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 experience with doctor\n",
      "1 advice give prospective patient\n",
      "2 experience with nurse\n",
      "3 experience with clinic\n",
      "4 protocols and success\n",
      "5 cost\n",
      "6 eSET vs. multiple embryo transfer\n",
      "7 specific things went wrong\n"
     ]
    }
   ],
   "source": [
    "for i,q in enumerate (df_t.Question.unique()):\n",
    "    #if type(q)==float:\n",
    "    print (i, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def failed_list(text):\n",
    "    if \"<ul\" in text:\n",
    "        text_list = text.split(\">\")\n",
    "        fail_list =[]\n",
    "        for i in text_list:\n",
    "            if \"</li\" in i:\n",
    "                fail_list.append(i.split('<')[0])\n",
    "        doc = ', '.join(fail_list)\n",
    "        return doc\n",
    "    \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.Answer = df_t.Answer.apply(failed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t.to_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clinic_name</th>\n",
       "      <th>clinic_score</th>\n",
       "      <th>doc_score</th>\n",
       "      <th>success</th>\n",
       "      <th>income</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>?</td>\n",
       "      <td>$100K - $199K</td>\n",
       "      <td>experience with doctor at clinic</td>\n",
       "      <td>Again, I only saw her once and she responded t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>experience with doctor at clinic</td>\n",
       "      <td>Dr. Grossman as an individual is compassionate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>experience with doctor at clinic</td>\n",
       "      <td>Communication skills are poor. Next steps were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>experience with doctor at clinic</td>\n",
       "      <td>I don't know if Dr. Rackow is really familiar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>experience with doctor at clinic</td>\n",
       "      <td>Dr. McConnell seemed like a warm person and sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14630</th>\n",
       "      <td>RMA of New Jersey</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>specific things that went wrong</td>\n",
       "      <td>[&lt;ul class=\"reviewer-clinic-fails__list\"&gt;&lt;li c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14631</th>\n",
       "      <td>RMA of New Jersey</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>—</td>\n",
       "      <td>specific things that went wrong</td>\n",
       "      <td>[&lt;ul class=\"reviewer-clinic-fails__list\"&gt;&lt;li c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14642</th>\n",
       "      <td>RMA of New Jersey</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>$200K - $499K</td>\n",
       "      <td>specific things that went wrong</td>\n",
       "      <td>[&lt;ul class=\"reviewer-clinic-fails__list\"&gt;&lt;li c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14646</th>\n",
       "      <td>RMA of New Jersey</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>$50K - $99K</td>\n",
       "      <td>specific things that went wrong</td>\n",
       "      <td>[&lt;ul class=\"reviewer-clinic-fails__list\"&gt;&lt;li c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14647</th>\n",
       "      <td>RMA of New Jersey</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>$100K - $199K</td>\n",
       "      <td>specific things that went wrong</td>\n",
       "      <td>[&lt;ul class=\"reviewer-clinic-fails__list\"&gt;&lt;li c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2241 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               clinic_name  clinic_score  doc_score success         income  \\\n",
       "10     Columbia University           7.0          4       ?  $100K - $199K   \n",
       "41     Columbia University           0.0          5      No  $200K - $499K   \n",
       "49     Columbia University           0.0          0      No  $200K - $499K   \n",
       "50     Columbia University           0.0          0      No  $200K - $499K   \n",
       "51     Columbia University           1.0          0      No  $200K - $499K   \n",
       "...                    ...           ...        ...     ...            ...   \n",
       "14630    RMA of New Jersey           3.0          6      No  $200K - $499K   \n",
       "14631    RMA of New Jersey           6.0          5      No              —   \n",
       "14642    RMA of New Jersey           5.0          5      No  $200K - $499K   \n",
       "14646    RMA of New Jersey           2.0          6     Yes    $50K - $99K   \n",
       "14647    RMA of New Jersey           5.0          5      No  $100K - $199K   \n",
       "\n",
       "                               Question  \\\n",
       "10     experience with doctor at clinic   \n",
       "41     experience with doctor at clinic   \n",
       "49     experience with doctor at clinic   \n",
       "50     experience with doctor at clinic   \n",
       "51     experience with doctor at clinic   \n",
       "...                                 ...   \n",
       "14630   specific things that went wrong   \n",
       "14631   specific things that went wrong   \n",
       "14642   specific things that went wrong   \n",
       "14646   specific things that went wrong   \n",
       "14647   specific things that went wrong   \n",
       "\n",
       "                                                  Answer  \n",
       "10     Again, I only saw her once and she responded t...  \n",
       "41     Dr. Grossman as an individual is compassionate...  \n",
       "49     Communication skills are poor. Next steps were...  \n",
       "50     I don't know if Dr. Rackow is really familiar ...  \n",
       "51     Dr. McConnell seemed like a warm person and sh...  \n",
       "...                                                  ...  \n",
       "14630  [<ul class=\"reviewer-clinic-fails__list\"><li c...  \n",
       "14631  [<ul class=\"reviewer-clinic-fails__list\"><li c...  \n",
       "14642  [<ul class=\"reviewer-clinic-fails__list\"><li c...  \n",
       "14646  [<ul class=\"reviewer-clinic-fails__list\"><li c...  \n",
       "14647  [<ul class=\"reviewer-clinic-fails__list\"><li c...  \n",
       "\n",
       "[2241 rows x 7 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t[df_t.doc_score<7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean answers\n",
    "# remove common words and stopwords\n",
    "\n",
    "# Remove words from data that are too common\n",
    "def remove_common_words(val):\n",
    "    list_of_common_words = ['time','questions','really','ask',\n",
    "                            'know','patients','think','said','day']\n",
    "    for i in range(len(list_of_common_words)):\n",
    "        val = val.replace(list_of_common_words[i],'')\n",
    "    return val\n",
    "\n",
    "df['text_string'] = df.text_string.apply(remove_common_words)\n",
    "\n",
    "df['text_string'] = df['text_string'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "# Convert the titles to lowercase\n",
    "df['text_string'] = df['text_string'].map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean scraped data\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    #doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_text = df_t.Answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dr. Rudick is very professional and knowledgeable. She never pushed me to do something I was not ready to do, and let me set the pace of my treatments. When I decided to take a short break between cycles, she was very understanding. She is also very straight forward and matter-of fact with results and reasons for those results, and she doesn't sugar-coat, which I appreciated and which added to my trust of her. When I received bad news after a few cycles back to back, Dr. Rudick sent me a very nice email and I felt that we were  in this together, working toward a common goal. Although Dr. Rudick was not always available at every visit, all of the doctors and nurses at Columbia were pleasant to work with. Before and during each procedure, Dr. Rudick would explain each step in detail, which helped ease my anxiety. I felt very cared for by her and the team at Columbia.\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_doc = nlp(intro_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Rudick is very professional and knowledgeable. She never pushed me to do something I was not ready to do, and let me set the pace of my treatments. When I decided to take a short break between cycles, she was very understanding. She is also very straight forward and matter-of fact with results and reasons for those results, and she doesn't sugar-coat, which I appreciated and which added to my trust of her. When I received bad news after a few cycles back to back, Dr. Rudick sent me a very nice email and I felt that we were  in this together, working toward a common goal. Although Dr. Rudick was not always available at every visit, all of the doctors and nurses at Columbia were pleasant to work with. Before and during each procedure, Dr. Rudick would explain each step in detail, which helped ease my anxiety. I felt very cared for by her and the team at Columbia."
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 convert text to spacy doc object\n",
    "def spacy_doc (text):\n",
    "    return nlp(text)\n",
    "# Step 2 either convert into sentences or remove stopwords\n",
    "\n",
    "# Step 3 Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(intro_doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dr. Rudick is very professional and knowledgeable.,\n",
       " She never pushed me to do something I was not ready to do, and let me set the pace of my treatments.,\n",
       " When I decided to take a short break between cycles, she was very understanding.,\n",
       " She is also very straight forward and matter-of fact with results and reasons for those results, and she doesn't sugar-coat, which I appreciated and which added to my trust of her.,\n",
       " When I received bad news after a few cycles back to back, Dr. Rudick sent me a very nice email and I felt that we were  in this together, working toward a common goal.,\n",
       " Although Dr. Rudick was not always available at every visit, all of the doctors and nurses at Columbia were pleasant to work with.,\n",
       " Before and during each procedure, Dr. Rudick would explain each step in detail, which helped ease my anxiety.,\n",
       " I felt very cared for by her and the team at Columbia.]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    punc_list = ['.',',',\"!\",'*','?','-']\n",
    "    text = ''.join(char for char in text if char not in punc_list)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jacobberger/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/topic-modelling-in-python-with-nltk-and-gensim-4ef03213cd21\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "def get_lemma(word):\n",
    "    lemma = wn.morphy(word)\n",
    "    if lemma is None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemma\n",
    "    \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def get_lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of words to not remove\n",
    "remove_form_stop_words = ['no','not',\"aren't\",\"couldn't\",\"didn't\",\"doesn't\",\n",
    "                          \"wasn't\",\"wouldn't\",\"won't\"]\n",
    "for w in remove_form_stop_words:\n",
    "    en_stop.remove(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pycontractions import Contractions\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tokenize(intro_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_for_lda(text):\n",
    "    \n",
    "    text = remove_punc(text)\n",
    "    \n",
    "    tokens = tokenize(text)\n",
    "    \n",
    "    # Contractions\n",
    "    #tokens = [contractions.fix(token) for token in tokens if \"'\" in token]\n",
    "    #tokens = [token for token in tokens if len(token) > 2]\n",
    "    # Remove Stop Words\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    #Lemmatization\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answers = df_t.Answer.apply(prepare_text_for_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(df_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in df_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "NUM_TOPICS = 8\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#import en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "# Lemmatize\n",
    "# Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "# Function to clean scraped data\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    #doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "def remove_punc(text):\n",
    "    punc_list = ['.',',',\"!\",'*','?','-']\n",
    "    text = ''.join(char for char in text if char not in punc_list)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['answers'] = data.Answer.apply(normalize_document)\n",
    "data['answers'] = data.answers.apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        dr  rudick professional knowledgeable  never p...\n",
       "1        dr  forman listened concerns good first time i...\n",
       "2        ' enough words describe amazing dr  eric forma...\n",
       "3        level contact patience patient goes beyond doc...\n",
       "4        physician  impressed dr  brady ' clinical know...\n",
       "                               ...                        \n",
       "14645                                    lost appointments\n",
       "14646    failed order appropriate test  failed send cha...\n",
       "14647                     provided conflicting information\n",
       "14648                     provided conflicting information\n",
       "14649                        failed order appropriate test\n",
       "Name: answers, Length: 14650, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "nlp= spacy.load(\"en\")\n",
    "def lemmatizer(doc):\n",
    "    # This takes in a doc of tokens from the NER and lemmatizes them. \n",
    "    # Pronouns (like \"I\" and \"you\" get lemmatized to '-PRON-', so I'm removing those.\n",
    "    doc = [token.lemma_ for token in doc if token.lemma_ != '-PRON-']\n",
    "    doc = u' '.join(doc)\n",
    "    return nlp.make_doc(doc)\n",
    "    \n",
    "def remove_stopwords(doc):\n",
    "    nlp= spacy.load(\"en\")\n",
    "    # This will remove stopwords and punctuation.\n",
    "    # Use token.text to return strings, which we'll need for Gensim.\n",
    "    doc = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. Rudick be very professional and knowledgeable . never push to do something be not ready to do , and let set the pace of treatment . when decide to take a short break between cycle , be very understanding . be also very straight forward and matter - of fact with result and reason for those result , and do not sugar - coat , which appreciate and which add to trust of . when receive bad news after a few cycle back to back , Dr. Rudick send a very nice email and feel that be   in this together , work toward a common goal . although Dr. Rudick be not always available at every visit , all of the doctor and nurse at Columbia be pleasant to work with . before and during each procedure , Dr. Rudick would explain each step in detail , which help ease anxiety . feel very care for by and the team at Columbia ."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer(nlp(data.Answer[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    if type(text) == str:\n",
    "        text = re.sub('<[^>]*>', '', text)\n",
    "        text = re.sub('[\\W]+', '', text.lower())\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def spacy_clean_text(review):\n",
    "                 \n",
    "    nlp = English()\n",
    "    tokenizer = nlp.Defaults.create_tokenizer(nlp)\n",
    "    tokens = tokenizer(review)\n",
    "    \n",
    "    lemma_list = []\n",
    "    n=0\n",
    "    for token in tokens:\n",
    "        if token.is_stop is False:\n",
    "            token_preprocessed = preprocessor(token.lemma_)\n",
    "            if token_preprocessed != '':\n",
    "                lemma_list.append(token_preprocessed) \n",
    "                \n",
    "    return (lemma_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['token_answers'] = data.Answer.apply(spacy_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('reviews_token.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_token(text):\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text'] = data.token_answers.apply(combine_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                  2059\n",
       "clinic_name                  Columbia University\n",
       "clinic_score                                   0\n",
       "doc_score                                      0\n",
       "success                                       No\n",
       "income                                         —\n",
       "Question         advice give prospective patient\n",
       "Answer                             Go elsewhere.\n",
       "answers                            go elsewhere \n",
       "token_answers                                 []\n",
       "clean_text                                      \n",
       "Name: 2059, dtype: object"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[2059]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(data.clean_text, data.Question, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bow = vec.fit_transform(data.clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit_transform(data_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer()),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 132    0    0   46  367    0    1    0]\n",
      " [   0  434    0   25   21    0    4    0]\n",
      " [   1    2  123    2  107    0    9    0]\n",
      " [   0    1    0  820  187    0    1    0]\n",
      " [   0    0    0   60 1100    1    6    0]\n",
      " [   0    0    0  131  164   11    0    0]\n",
      " [   1    4    0    1   97    0  361    0]\n",
      " [   0    0    0    0    0    0    0  175]]\n",
      "\n",
      "\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "  advice give prospective patient       0.99      0.24      0.39       546\n",
      "                             cost       0.98      0.90      0.94       484\n",
      "eSET vs. multiple embryo transfer       1.00      0.50      0.67       244\n",
      "           experience with clinic       0.76      0.81      0.78      1009\n",
      "           experience with doctor       0.54      0.94      0.69      1167\n",
      "            experience with nurse       0.92      0.04      0.07       306\n",
      "            protocols and success       0.95      0.78      0.85       464\n",
      "       specific things went wrong       1.00      1.00      1.00       175\n",
      "\n",
      "                         accuracy                           0.72      4395\n",
      "                        macro avg       0.89      0.65      0.67      4395\n",
      "                     weighted avg       0.81      0.72      0.69      4395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(label_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.countplot(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = MultinomialNB().fit(tfidf_transformer, data.Question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_bow = vec.transform(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_tfidf = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
